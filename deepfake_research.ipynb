{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e879bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def writeToFile(papers_by_year, save_path, field_names):\n",
    "    with open(save_path, \"w+\") as file:\n",
    "        csvWriter = csv.writer(file, delimiter=\",\")\n",
    "        csvWriter.writerow(field_names)\n",
    "        for key in papers_by_year.keys():\n",
    "            file.write(\"%s, %s\\n\" % (key, papers_by_year[key]))\n",
    "\n",
    "\n",
    "def fetchDeepfakePapers(query):\n",
    "    papers_by_year = {}\n",
    "    for year in range(2000, 2023):\n",
    "        result = requests.get(\n",
    "            \"http://api.semanticscholar.org/graph/v1/paper/search?query={}&year={}\".format(\n",
    "                query, year\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if result.reason != \"OK\":\n",
    "            print(\"Error: \", result.status_code, result.reason)\n",
    "            exit\n",
    "\n",
    "        paper_records = result.json()\n",
    "        num_papers = paper_records[\"total\"]\n",
    "        print(\"Total number of {} papers in {}: {}\".format(query, year, num_papers))\n",
    "        papers_by_year[year] = num_papers\n",
    "\n",
    "        return papers_by_year\n",
    "\n",
    "\n",
    "def plotData(file, title):\n",
    "    df = pd.read_csv(file)\n",
    "    fig = px.line(df, y=df.columns, x=\"Year\", title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbba76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_file = \"num_deepfake_papers_by_year.csv\"\n",
    "deepfake_ethics_file = \"num_deepfake_ethics_papers_by_year.csv\"\n",
    "combined_file = \"combined_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6e678",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_papers_by_year = fetchDeepfakePapers(\"deepfake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_ethics_papers_by_year = fetchDeepfakePapers(\"deepfake+ethic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851d7fe",
   "metadata": {},
   "source": [
    "# Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile(deepfake_papers_by_year, save_path=deepfake_file, field_names=[\"Year\", \"NumPapers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff259c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile(deepfake_ethics_papers_by_year, save_path=deepfake_ethics_file, field_names=[\"Year\", \"NumPapers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a182dc",
   "metadata": {},
   "source": [
    "# Plot all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(deepfake_file, \"Number of Deepfake Paper Publications Over Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe947425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(deepfake_ethics_file, \"Number of Deepfake Paper Publications With Ethical Considerations Over Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(\n",
    "    combined_file,\n",
    "    \"Number of Deepfake Paper Publications With Ethical Considerations Over Time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e9460",
   "metadata": {},
   "source": [
    "# Normalize combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5337cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data     NumDeepfakePapers  NumDeepfakeEthicsPapers\n",
      "0             3194825                  3195467\n",
      "1             3385868                  3386666\n",
      "2             3667076                  3667889\n",
      "3             3991471                  3992497\n",
      "4             4526587                  4527751\n",
      "5             4880192                  4881486\n",
      "6             5236653                  5238099\n",
      "7             5659088                  5660620\n",
      "8             6123537                  6125139\n",
      "9             6594526                  6596070\n",
      "10            7038482                  7040315\n",
      "11            7467256                  7469109\n",
      "12            7820983                  7822787\n",
      "13            8206144                  8207971\n",
      "14            8419942                  8421936\n",
      "15            8649157                  8651075\n",
      "16            8700248                  8702273\n",
      "17            8255706                  8257552\n",
      "18            8205111                  8206978\n",
      "19            8366227                  8368076\n",
      "20            8432825                  8434442\n",
      "21            6983408                  6984485\n",
      "22            4676906                  4677596\n",
      "Normalized data [[0.         0.        ]\n",
      " [0.03470088 0.03472049]\n",
      " [0.08577924 0.08578875]\n",
      " [0.14470205 0.14473544]\n",
      " [0.24190003 0.24193407]\n",
      " [0.30612852 0.30617004]\n",
      " [0.37087577 0.37092863]\n",
      " [0.44760648 0.44765568]\n",
      " [0.53196857 0.5320093 ]\n",
      " [0.61751858 0.61752729]\n",
      " [0.69815834 0.69819928]\n",
      " [0.77604046 0.77606547]\n",
      " [0.84029111 0.84029109]\n",
      " [0.9102514  0.91023799]\n",
      " [0.94908547 0.94909263]\n",
      " [0.99071988 0.99070278]\n",
      " [1.         1.        ]\n",
      " [0.9192538  0.91924157]\n",
      " [0.91006377 0.91005766]\n",
      " [0.93932873 0.93931201]\n",
      " [0.95142553 0.95136364]\n",
      " [0.68815475 0.68806092]\n",
      " [0.26920384 0.26914495]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(combined_file)\n",
    "df = df[[\"NumDeepfakePapers\", \"NumDeepfakeEthicsPapers\"]] #returns a numpy array\n",
    "print(\"Original data\", df)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dfScaled = min_max_scaler.fit_transform(df)\n",
    "print(\"Normalized data\", dfScaled)\n",
    "\n",
    "np.savetxt(\"combinded_data_normalized.csv\", dfScaled, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
