{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e879bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def writeToFile(papers_by_year, save_path, field_names):\n",
    "    with open(save_path, \"w+\") as file:\n",
    "        csvWriter = csv.writer(file, delimiter=\",\")\n",
    "        csvWriter.writerow(field_names)\n",
    "        for key in papers_by_year.keys():\n",
    "            file.write(\"%s, %s\\n\" % (key, papers_by_year[key]))\n",
    "\n",
    "\n",
    "def fetchDeepfakePapers(query):\n",
    "    papers_by_year = {}\n",
    "    for year in range(2000, 2023):\n",
    "        result = requests.get(\n",
    "            \"http://api.semanticscholar.org/graph/v1/paper/search?query={}&year={}\".format(\n",
    "                query, year\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if result.reason != \"OK\":\n",
    "            print(\"Error: \", result.status_code, result.reason)\n",
    "            exit\n",
    "\n",
    "        paper_records = result.json()\n",
    "        num_papers = paper_records[\"total\"]\n",
    "        print(\"Total number of {} papers in {}: {}\".format(query, year, num_papers))\n",
    "        papers_by_year[year] = num_papers\n",
    "\n",
    "    return papers_by_year\n",
    "\n",
    "\n",
    "def plotData(file, title):\n",
    "    df = pd.read_csv(file)\n",
    "    fig = px.line(df, y=df.columns, x=\"Year\", title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbba76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_file = \"num_deepfake_papers_by_year.csv\"\n",
    "deepfake_ethics_file = \"num_deepfake_ethics_papers_by_year.csv\"\n",
    "combined_file = \"combined_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6e678",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ca7848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of deepfake papers in 2000: 3195572\n",
      "Total number of deepfake papers in 2001: 3386495\n",
      "Total number of deepfake papers in 2002: 3667697\n",
      "Total number of deepfake papers in 2003: 3992280\n",
      "Total number of deepfake papers in 2004: 4527191\n",
      "Total number of deepfake papers in 2005: 4880496\n",
      "Total number of deepfake papers in 2006: 5237360\n",
      "Total number of deepfake papers in 2007: 5659861\n",
      "Total number of deepfake papers in 2008: 6124292\n",
      "Total number of deepfake papers in 2009: 6595595\n",
      "Total number of deepfake papers in 2010: 7041065\n",
      "Total number of deepfake papers in 2011: 7489358\n",
      "Total number of deepfake papers in 2012: 7873383\n",
      "Total number of deepfake papers in 2013: 8258101\n",
      "Total number of deepfake papers in 2014: 8473786\n",
      "Total number of deepfake papers in 2015: 8703265\n",
      "Total number of deepfake papers in 2016: 8757283\n",
      "Total number of deepfake papers in 2017: 8311604\n",
      "Total number of deepfake papers in 2018: 8261492\n",
      "Total number of deepfake papers in 2019: 8408090\n",
      "Total number of deepfake papers in 2020: 8466329\n",
      "Total number of deepfake papers in 2021: 7011093\n",
      "Total number of deepfake papers in 2022: 5257940\n"
     ]
    }
   ],
   "source": [
    "deepfake_papers_by_year = fetchDeepfakePapers(\"deepfake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f02a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of deepfake+ethic papers in 2000: 3196212\n",
      "Total number of deepfake+ethic papers in 2001: 3387292\n",
      "Total number of deepfake+ethic papers in 2002: 3668510\n",
      "Total number of deepfake+ethic papers in 2003: 3993304\n",
      "Total number of deepfake+ethic papers in 2004: 4528357\n",
      "Total number of deepfake+ethic papers in 2005: 4881791\n",
      "Total number of deepfake+ethic papers in 2006: 5238802\n",
      "Total number of deepfake+ethic papers in 2007: 5661386\n",
      "Total number of deepfake+ethic papers in 2008: 6125894\n",
      "Total number of deepfake+ethic papers in 2009: 6597140\n",
      "Total number of deepfake+ethic papers in 2010: 7042901\n",
      "Total number of deepfake+ethic papers in 2011: 7491219\n",
      "Total number of deepfake+ethic papers in 2012: 7875216\n",
      "Total number of deepfake+ethic papers in 2013: 8259951\n",
      "Total number of deepfake+ethic papers in 2014: 8475799\n",
      "Total number of deepfake+ethic papers in 2015: 8705214\n",
      "Total number of deepfake+ethic papers in 2016: 8759346\n",
      "Total number of deepfake+ethic papers in 2017: 8313493\n",
      "Total number of deepfake+ethic papers in 2018: 8263382\n",
      "Total number of deepfake+ethic papers in 2019: 8409946\n",
      "Total number of deepfake+ethic papers in 2020: 8467972\n",
      "Total number of deepfake+ethic papers in 2021: 7012169\n",
      "Total number of deepfake+ethic papers in 2022: 5258421\n"
     ]
    }
   ],
   "source": [
    "deepfake_ethics_papers_by_year = fetchDeepfakePapers(\"deepfake+ethic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851d7fe",
   "metadata": {},
   "source": [
    "# Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b9900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile(deepfake_papers_by_year, save_path=deepfake_file, field_names=[\"Year\", \"NumPapers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff259c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile(deepfake_ethics_papers_by_year, save_path=deepfake_ethics_file, field_names=[\"Year\", \"NumPapers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a182dc",
   "metadata": {},
   "source": [
    "# Plot all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(deepfake_file, \"Number of Deepfake Paper Publications Over Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe947425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(deepfake_ethics_file, \"Number of Deepfake Paper Publications With Ethical Considerations Over Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(\n",
    "    combined_file,\n",
    "    \"Number of Deepfake Paper Publications With Ethical Considerations Over Time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e9460",
   "metadata": {},
   "source": [
    "# Normalize combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(combined_file)\n",
    "df = df[[\"NumDeepfakePapers\", \"NumDeepfakeEthicsPapers\"]] #returns a numpy array\n",
    "print(\"Original data\", df)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dfScaled = min_max_scaler.fit_transform(df)\n",
    "print(\"Normalized data\", dfScaled)\n",
    "\n",
    "np.savetxt(\"combinded_data_normalized.csv\", dfScaled, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb536360",
   "metadata": {},
   "source": [
    "# Most cited deepfake papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from S2search import S2paperWeb\n",
    "m = S2paperWeb()\n",
    "numEntries = 5\n",
    "m.get(\"deepfake\", n=numEntries, sort=\"total-citations\")\n",
    "for i in range(0, numEntries):\n",
    "    id = m.all['Results'][0]['Page']['Papers'][i][\"id\"]\n",
    "    numCitations = m.all['Results'][0]['Page']['Papers'][i][\"citationStats\"][\"numCitations\"]\n",
    "    print(\"Paper \", id, \" has \", numCitations, \" citations.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98e9c14e",
   "metadata": {},
   "source": [
    "# Most prolific institutions for deepfake research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_cited_papers = [\"37033b779765b5ed3b3eaaf8e1d5c5a62ff02e85\", \"2d066beb34469559e0fc5e5ab4d68dc736cfd46f\", \"300d08e8f5c310c2b194b7eb94398e480994d5cc\", \"3d26fb6e819a79b6abd4964d8d96314e74f73423\", \"2cdb1b96846609a965496236eaccb54b1790daab\"]\n",
    "papers_by_institution = {}\n",
    "# for every prolific paper...\n",
    "for paper in most_cited_papers:\n",
    "    result = requests.get(\n",
    "        \"https://api.semanticscholar.org/graph/v1/paper/{id}/authors\".format(\n",
    "            id=paper,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if result.reason != \"OK\":\n",
    "        print(\"Error: \", result.status_code, result.reason)\n",
    "        exit\n",
    "\n",
    "    authors = result.json()[\"data\"]\n",
    "    # for every one of its authors...\n",
    "    for i in range(0, len(authors)):\n",
    "        id = authors[i][\"authorId\"]\n",
    "        result = requests.get(\"https://api.semanticscholar.org/graph/v1/author/{id}?fields=affiliations\".format(\n",
    "            id=id)\n",
    "        )\n",
    "    \n",
    "        # for every author's affiliations...\n",
    "        if result.reason != \"OK\":\n",
    "            print(\"Error: \", result.status_code, result.reason)\n",
    "            exit\n",
    "            \n",
    "        affiliations = result.json()[\"affiliations\"]\n",
    "        for a in affiliations:\n",
    "            if a in papers_by_institution:\n",
    "                papers_by_institution[a] += 1\n",
    "            else:\n",
    "                papers_by_institution[a] = 1\n",
    "                \n",
    "print(papers_by_institution)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
